{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version trains using the MNIST dataset, then tests on our own images\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with our own image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... my_own_images/2828_my_verify_code_5.png\n",
      "min =  0.01\n",
      "max =  0.879647\n",
      "[[ 0.11417934]\n",
      " [ 0.03061609]\n",
      " [ 0.03027998]\n",
      " [ 0.44070137]\n",
      " [ 0.07811867]\n",
      " [ 0.03220935]\n",
      " [ 0.06210584]\n",
      " [ 0.00842277]\n",
      " [ 0.06346339]\n",
      " [ 0.02216428]]\n",
      "network says  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9f9DVeJLnfSNkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b7cf86d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network withour own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... my_own_images/2828_my_verify_code_5.png\")\n",
    "img_array = scipy.misc.imread('my_own_images/2828_my_verify_code_5.png', flatten=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "print(\"min = \", numpy.min(img_data))\n",
    "print(\"max = \", numpy.max(img_data))\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
